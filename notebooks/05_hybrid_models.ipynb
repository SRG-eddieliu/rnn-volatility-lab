{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Hybrid Models (GARCH + RNN)\n",
    "\n",
    "This notebook trains both hybrid architectures with `MSE` training loss:\n",
    "- Hybrid LSTM\n",
    "- Hybrid GRU\n",
    "\n",
    "Evaluation remains on both `MSE` and `QLIKE`.\n",
    "Hybrid inputs are Pure-RNN features plus `garch_cond_var` from rolling GARCH(1,1)-t forecasts.\n",
    "Training checkpoints predictions/logs/gates after each split and supports resume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.evaluation import evaluate_forecasts\n",
    "from src.models.garch import add_garch_feature\n",
    "from src.models.rnn import RNNTrainingConfig, run_rolling_experiment\n",
    "from src.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = PROJECT_ROOT / \"data\" / \"processed\" / \"sp500_log_returns.csv\"\n",
    "splits_path = PROJECT_ROOT / \"data\" / \"processed\" / \"rolling_splits.csv\"\n",
    "\n",
    "base_df = pd.read_csv(data_path, parse_dates=[\"date\"])\n",
    "splits_df = pd.read_csv(\n",
    "    splits_path,\n",
    "    parse_dates=[\n",
    "        \"train_start_date\",\n",
    "        \"train_end_date\",\n",
    "        \"val_start_date\",\n",
    "        \"val_end_date\",\n",
    "        \"test_start_date\",\n",
    "        \"test_end_date\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "pred_dir = PROJECT_ROOT / \"reports\" / \"predictions\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lstm_pred_path = pred_dir / \"hybrid_lstm_predictions.csv\"\n",
    "lstm_log_path = pred_dir / \"hybrid_lstm_train_logs.csv\"\n",
    "lstm_gate_path = pred_dir / \"hybrid_lstm_gate_values.csv\"\n",
    "\n",
    "gru_pred_path = pred_dir / \"hybrid_gru_predictions.csv\"\n",
    "gru_log_path = pred_dir / \"hybrid_gru_train_logs.csv\"\n",
    "gru_gate_path = pred_dir / \"hybrid_gru_gate_values.csv\"\n",
    "\n",
    "base_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling GARCH forecasts are computed without lookahead and added as a feature.\n",
    "hybrid_df = add_garch_feature(\n",
    "    base_df,\n",
    "    return_col=\"log_return\",\n",
    "    out_col=\"garch_cond_var\",\n",
    "    min_train_size=756,\n",
    "    refit_every=21,\n",
    ")\n",
    "\n",
    "hybrid_data_path = PROJECT_ROOT / \"data\" / \"processed\" / \"sp500_log_returns_with_garch.csv\"\n",
    "hybrid_df.to_csv(hybrid_data_path, index=False)\n",
    "print(f\"Saved hybrid feature dataset: {hybrid_data_path}\")\n",
    "\n",
    "hybrid_df[[\"date\", \"log_return\", \"garch_cond_var\"]].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = RNNTrainingConfig(\n",
    "    lookback=21,\n",
    "    hidden_units=8,\n",
    "    dropout=0.10,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    epochs=35,\n",
    "    patience=6,\n",
    "    seed=42,\n",
    ")\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_lstm_pred, hybrid_lstm_logs, hybrid_lstm_gates, hybrid_lstm_last_history = run_rolling_experiment(\n",
    "    df=hybrid_df,\n",
    "    splits_df=splits_df,\n",
    "    architecture=\"lstm\",\n",
    "    variant=\"hybrid\",\n",
    "    cfg=cfg,\n",
    "    verbose_fit=0,\n",
    "    capture_gates=True,\n",
    "    predictions_path=lstm_pred_path,\n",
    "    train_logs_path=lstm_log_path,\n",
    "    gates_path=lstm_gate_path,\n",
    "    resume=False,\n",
    "    collect_last_history=True,\n",
    ")\n",
    "\n",
    "hybrid_lstm_metrics = evaluate_forecasts(\n",
    "    hybrid_lstm_pred,\n",
    "    group_cols=[\"variant\", \"architecture\", \"train_loss\"],\n",
    ")\n",
    "hybrid_lstm_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_gru_pred, hybrid_gru_logs, hybrid_gru_gates, hybrid_gru_last_history = run_rolling_experiment(\n",
    "    df=hybrid_df,\n",
    "    splits_df=splits_df,\n",
    "    architecture=\"gru\",\n",
    "    variant=\"hybrid\",\n",
    "    cfg=cfg,\n",
    "    verbose_fit=0,\n",
    "    capture_gates=True,\n",
    "    predictions_path=gru_pred_path,\n",
    "    train_logs_path=gru_log_path,\n",
    "    gates_path=gru_gate_path,\n",
    "    resume=False,\n",
    "    collect_last_history=True,\n",
    ")\n",
    "\n",
    "hybrid_gru_metrics = evaluate_forecasts(\n",
    "    hybrid_gru_pred,\n",
    "    group_cols=[\"variant\", \"architecture\", \"train_loss\"],\n",
    ")\n",
    "hybrid_gru_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved hybrid prediction, training log, and gate-value files in reports/predictions\")\n",
    "print(f\"LSTM files: {lstm_pred_path}, {lstm_log_path}, {lstm_gate_path}\")\n",
    "print(f\"GRU files: {gru_pred_path}, {gru_log_path}, {gru_gate_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting diagnostics: train vs validation loss across rolling splits.\n",
    "log_frames = []\n",
    "for model_name, logs in [(\"hybrid_lstm\", hybrid_lstm_logs), (\"hybrid_gru\", hybrid_gru_logs)]:\n",
    "    d = logs.copy()\n",
    "    d[\"model_name\"] = model_name\n",
    "    log_frames.append(d)\n",
    "\n",
    "log_plot = pd.concat(log_frames, ignore_index=True)\n",
    "required_cols = {\n",
    "    \"split_id\",\n",
    "    \"model_name\",\n",
    "    \"best_train_loss\",\n",
    "    \"best_val_loss\",\n",
    "    \"best_gap_val_minus_train\",\n",
    "}\n",
    "missing = sorted(required_cols.difference(log_plot.columns))\n",
    "if missing:\n",
    "    print(\n",
    "        \"Train log is missing aggregate diagnostics columns. \"\n",
    "        \"Using last trained split histories instead. \"\n",
    "        f\"Missing: {missing}\"\n",
    "    )\n",
    "else:\n",
    "    log_plot = log_plot.sort_values([\"model_name\", \"split_id\"]).reset_index(drop=True)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 9), sharex=True)\n",
    "\n",
    "    for model_name, d in log_plot.groupby(\"model_name\"):\n",
    "        axes[0].plot(d[\"split_id\"], d[\"best_train_loss\"], linewidth=1.1, label=f\"{model_name} train\")\n",
    "        axes[0].plot(d[\"split_id\"], d[\"best_val_loss\"], linewidth=1.1, linestyle=\"--\", label=f\"{model_name} val\")\n",
    "\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Best Train/Val Loss by Rolling Split\")\n",
    "    axes[0].grid(alpha=0.2)\n",
    "    axes[0].legend(ncol=2)\n",
    "\n",
    "    for model_name, d in log_plot.groupby(\"model_name\"):\n",
    "        axes[1].plot(d[\"split_id\"], d[\"best_gap_val_minus_train\"], linewidth=1.2, label=model_name)\n",
    "\n",
    "    axes[1].axhline(0.0, color=\"gray\", linestyle=\"--\", linewidth=1.0)\n",
    "    axes[1].set_xlabel(\"Split ID\")\n",
    "    axes[1].set_ylabel(\"Gap\")\n",
    "    axes[1].set_title(\"Overfit Gap by Rolling Split (Best Epoch)\")\n",
    "    axes[1].grid(alpha=0.2)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for model_name, hist in [(\"hybrid_lstm\", hybrid_lstm_last_history), (\"hybrid_gru\", hybrid_gru_last_history)]:\n",
    "    if hist is None:\n",
    "        print(\n",
    "            f\"No last split history for {model_name}. \"\n",
    "            \"If resume=True and no new split was trained, set resume=False (or clear outputs) and rerun.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    hist_df = pd.DataFrame(\n",
    "        {\n",
    "            \"epoch\": range(1, len(hist[\"loss\"]) + 1),\n",
    "            \"train_loss\": hist[\"loss\"],\n",
    "            \"val_loss\": hist[\"val_loss\"],\n",
    "        }\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    ax.plot(hist_df[\"epoch\"], hist_df[\"train_loss\"], label=\"Train Loss\", linewidth=1.4)\n",
    "    ax.plot(hist_df[\"epoch\"], hist_df[\"val_loss\"], label=\"Validation Loss\", linewidth=1.4)\n",
    "    ax.set_title(f\"{model_name} Last Split Loss Curves (split_id={hist['split_id']})\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.grid(alpha=0.2)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}